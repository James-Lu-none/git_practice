{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import *\n",
    "from keras.engine.training import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "current_file_path = Path(get_ipython().run_line_magic('pwd', ''))\n",
    "root_path = current_file_path\n",
    "while not any(file.suffix == \".ipynb\" for file in root_path.glob(\"*\")):\n",
    "    root_path = root_path.parent\n",
    "\n",
    "root_path = str(root_path)\n",
    "print(root_path)\n",
    "\n",
    "\n",
    "board_width = 15\n",
    "board_height = 15\n",
    "last_n_feature=1\n",
    "input_shape=(4+last_n_feature,  board_width,  board_height)\n",
    "l2_const = 1e-4\n",
    "batch_size=512\n",
    "epochs=50\n",
    "init_lr=1e-4\n",
    "is_load_model=False\n",
    "take_last_n_move=5\n",
    "load_model_dir=None# xx_xx_xxxxxx\n",
    "sample_size=4 #games\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(root_path,f'self_play_data')\n",
    "data_files = os.listdir(data_dir)\n",
    "data = []\n",
    "for file in data_files:\n",
    "    print(f\"loading file {file}...\")\n",
    "    file = os.path.join(data_dir,file)\n",
    "    with open(file, 'rb') as f:\n",
    "        data += pickle.load(f)\n",
    "    print(f\"file {file} loaded\")\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = []\n",
    "probs = []\n",
    "wins = []\n",
    "result = []\n",
    "moves = []\n",
    "print(len(data))\n",
    "data=random.sample(data,sample_size)\n",
    "print(len(data))\n",
    "# print(data)\n",
    "for idx,i in enumerate(data):\n",
    "    print(idx,len(i))\n",
    "\n",
    "for move in data:\n",
    "    moves.append(move)\n",
    "random.shuffle(moves)\n",
    "print(moves)\n",
    "for i in moves:\n",
    "    print(i)\n",
    "    status.append(i[0])\n",
    "    probs.append(i[1])\n",
    "    wins.append(i[2])\n",
    "\n",
    "train_size = int(0.8*len(status))\n",
    "print(\"total status:{}\".format(len(status)))\n",
    "\n",
    "x_train = status[:train_size]\n",
    "x_test = status[train_size:]\n",
    "\n",
    "y_train_probs = probs[:train_size]\n",
    "y_test_probs = probs[train_size:]\n",
    "\n",
    "y_train_wins = wins[:train_size]\n",
    "y_test_wins = wins[train_size:]\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "\n",
    "x_train = np.asarray(x_train)\n",
    "x_test = np.asarray(x_test)\n",
    "\n",
    "y_train_probs = np.asarray(y_train_probs)\n",
    "y_train_probs = np.reshape(y_train_probs, (y_train_probs.shape[0], -1))\n",
    "y_train_wins = np.asarray(y_train_wins)\n",
    "\n",
    "y_test_probs = np.asarray(y_test_probs)\n",
    "y_test_probs = np.reshape(y_test_probs, (y_test_probs.shape[0], -1))\n",
    "y_test_wins = np.asarray(y_test_wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train[1][2])\n",
    "print(x_train[1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_structure(input_shape,l2_const):\n",
    "    \n",
    "    def resnext_block(inputs, filters, cardinality=32, strides=1):\n",
    "        x = Conv2D(filters, kernel_size=3,kernel_regularizer=l2(l2_const),\n",
    "                strides=strides,padding='same')(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(filters, kernel_size=3,kernel_regularizer=l2(l2_const),\n",
    "                strides=strides,padding='same')(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = add([inputs, x])\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "    in_x = network = Input(input_shape)\n",
    "    network = Conv2D(filters=64, kernel_size=3,kernel_regularizer=l2(l2_const),\n",
    "                          strides=1, padding='same')(network)\n",
    "    network = BatchNormalization()(network)\n",
    "    network = Activation('relu')(network)\n",
    "    network = resnext_block(network, 64)\n",
    "    network = resnext_block(network, 64)\n",
    "    network = resnext_block(network, 64)\n",
    "    network = resnext_block(network, 64)\n",
    "    network = resnext_block(network, 64)\n",
    "    network = resnext_block(network, 64)\n",
    "    network = resnext_block(network, 64)\n",
    "    # action policy layers\n",
    "    policy_net = Conv2D(filters=2, kernel_size=(1, 1), data_format=\"channels_first\",\n",
    "                        kernel_regularizer=l2(l2_const), name=\"policy_net_input\")(network)\n",
    "    policy_net = BatchNormalization()(policy_net)\n",
    "    policy_net = Activation(\"relu\")(policy_net)\n",
    "    policy_net = Flatten()(policy_net)\n",
    "    policy_net = Dense(board_width * board_height,\n",
    "                    activation=\"softmax\", kernel_regularizer=l2(l2_const), name=\"policy_net\")(policy_net)\n",
    "    # state value layers\n",
    "    value_net = Conv2D(filters=1, kernel_size=(1, 1), data_format=\"channels_first\",\n",
    "                    kernel_regularizer=l2(l2_const), name=\"value_net_input\")(network)\n",
    "    value_net = BatchNormalization()(value_net)\n",
    "    value_net = Activation(\"relu\")(value_net)\n",
    "    value_net = Flatten()(value_net)\n",
    "    value_net = Dense(256, kernel_regularizer=l2(l2_const))(value_net)\n",
    "    value_net = Activation(\"relu\",)(value_net)\n",
    "    value_net = Dense(1, activation=\"tanh\",\n",
    "                    kernel_regularizer=l2(l2_const), name=\"value_net\")(value_net)\n",
    "\n",
    "    model = Model(in_x, [policy_net,  value_net])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if(is_load_model):\n",
    "    model=load_model(os.path.join(root_path,'model_record',load_model_dir,'model.h5'))\n",
    "else:\n",
    "    model=model_structure(input_shape,l2_const)\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=init_lr,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "optimizer = Adam(\n",
    "    learning_rate=lr_schedule, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=['categorical_crossentropy', 'mean_squared_error'],\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    start_time=time.process_time()\n",
    "    history = model.fit(x_train,\n",
    "                    [y_train_probs, y_train_wins],\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, [y_test_probs, y_test_wins]))\n",
    "    precess_time=time.process_time()-start_time\n",
    "except KeyboardInterrupt as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=history\n",
    "\n",
    "policy_net_loss = result.history['policy_net_loss']\n",
    "policy_net_accuracy = result.history['policy_net_accuracy']\n",
    "val_policy_net_loss = result.history['val_policy_net_loss']\n",
    "val_policy_net_accuracy = result.history['val_policy_net_accuracy']\n",
    "\n",
    "value_net_loss = result.history['value_net_loss']\n",
    "value_net_accuracy = result.history['value_net_accuracy']\n",
    "val_value_net_loss = result.history['val_value_net_loss']\n",
    "val_value_net_accuracy = result.history['val_value_net_accuracy']\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Training and Validation Accuracy (policy_net)\")\n",
    "plt.plot(policy_net_accuracy, color='green', label='Training Acuracy')\n",
    "plt.plot(val_policy_net_accuracy, color='red', label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title('Training and Validation Loss (policy_net)')\n",
    "plt.plot(policy_net_loss, color='blue', label='Training Loss')\n",
    "plt.plot(val_policy_net_loss, color='purple', label='Validation Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"Training and Validation Accuracy (value_net)\")\n",
    "plt.plot(value_net_accuracy, color='green', label='Training Acuracy')\n",
    "plt.plot(val_value_net_accuracy, color='red', label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title('Training and Validation Loss (value_net)')\n",
    "plt.plot(value_net_loss, color='blue', label='Training Loss')\n",
    "plt.plot(val_value_net_loss, color='purple', label='Validation Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "score = model.evaluate(\n",
    "    x_test, [y_test_probs, y_test_wins], verbose=1)\n",
    "\n",
    "# print(\"Testing Accuracy = %.2f %%    loss = %f\" % (accuracy * 100, loss))\n",
    "fig=plt.gcf()\n",
    "plt.show()\n",
    "print(f\"policy val acc = {score[3]}\")\n",
    "print(f\"policy val loss = {score[1]}\")\n",
    "print(f\"value val acc = {score[4]}\")\n",
    "print(f\"value val loss = {score[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t = time.localtime()\n",
    "folder_name = f\"{t.tm_mon:0>2}_{t.tm_mday:0>2}_{t.tm_hour:0>2}{t.tm_min:0>2}{t.tm_sec:0>2}\"\n",
    "new_folder_dir=os.path.join(root_path,'model_record',folder_name)\n",
    "os.makedirs(new_folder_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_seconds(seconds):\n",
    "    seconds=int(seconds)\n",
    "    hours = seconds // 3600\n",
    "    minutes = (seconds % 3600) // 60\n",
    "    seconds = seconds % 60\n",
    "    return f\"{hours:0>3}h {minutes:0>2}m {seconds:0>2}s\"\n",
    "\n",
    "fig.savefig(os.path.join(new_folder_dir,'history.png'))\n",
    "model.save(os.path.join(new_folder_dir,'model.h5'))\n",
    "\n",
    "with open(os.path.join(new_folder_dir,'result.txt'), 'w') as f:\n",
    "    f.write(f\"load model = {is_load_model}\\n\")\n",
    "    f.write(f\"load model dir = {load_model_dir}\\n\")\n",
    "    f.write(f\"epochs = {epochs}\\n\")\n",
    "    f.write(f\"batch_size = {batch_size}\\n\")\n",
    "    f.write(f\"sample_size = {sample_size}\\n\")\n",
    "    f.write(f\"take_last_n_move = {take_last_n_move}\\n\")\n",
    "    f.write(f\"input_shape = {input_shape}\\n\")\n",
    "    f.write(f\"last_n_feature = {last_n_feature}\\n\")\n",
    "    f.write(f\"init lr = {init_lr}\\n\")\n",
    "    f.write(f\"l2 const = {l2_const}\\n\")\n",
    "    f.write(f\"policy val acc = {score[3]}\\n\")\n",
    "    f.write(f\"policy val loss = {score[1]}\\n\")\n",
    "    f.write(f\"value val acc = {score[4]}\\n\")\n",
    "    f.write(f\"value val loss = {score[2]}\\n\")\n",
    "    f.write(f\"precess time = {convert_seconds(precess_time)}\\n\")\n",
    "\n",
    "python_file_name=\"manual_data_training.ipynb\"\n",
    "with open(python_file_name) as f:\n",
    "    code = f.read()\n",
    "    f.close()\n",
    "json_code = json.loads(code)\n",
    "model_structure=json_code['cells'][4]\n",
    "with open(os.path.join(new_folder_dir,\"model_structure.txt\"), mode=\"w\") as f:\n",
    "    f.write(\"\".join(model_structure['source']))\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
